{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1272,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 3
      },
      {
       "item_id": 4
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5949,
     "status": "error",
     "timestamp": 1520760604752,
     "user": {
      "displayName": "Usama Riaz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100708119964800276422"
     },
     "user_tz": 480
    },
    "id": "sXz3vGTPs2ks",
    "outputId": "c2511b78-6bc7-4059-dd73-07d8a8428ccf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 10, 15)            16320     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 10, 256)           4096      \n",
      "=================================================================\n",
      "Total params: 20,416\n",
      "Trainable params: 20,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 5.5471 - acc: 0.0063\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "Generated string: ylIfewfyyV\n",
      "\n",
      "Epoch 00001: saving model to serialized_models/shakespeare_gen.h5\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.5392 - acc: 0.0094\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "Generated string: wfyya  p p\n",
      "\n",
      "Epoch 00002: saving model to serialized_models/shakespeare_gen.h5\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.5334 - acc: 0.0094\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "Generated string:  uuubbfbff\n",
      "\n",
      "Epoch 00003: saving model to serialized_models/shakespeare_gen.h5\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.5287 - acc: 0.0156\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "Generated string: i,aaa  dp\n",
      "\n",
      "\n",
      "Epoch 00004: saving model to serialized_models/shakespeare_gen.h5\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.5255 - acc: 0.0344\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "Generated string: ya ddpfyy \n",
      "\n",
      "Epoch 00005: saving model to serialized_models/shakespeare_gen.h5\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.5212 - acc: 0.0406\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "Generated string:  uuuuuubub\n",
      "\n",
      "Epoch 00006: saving model to serialized_models/shakespeare_gen.h5\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.5190 - acc: 0.0250\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "Generated string: Eddpyltddd\n",
      "\n",
      "Epoch 00007: saving model to serialized_models/shakespeare_gen.h5\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.5129 - acc: 0.0219\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "Generated string: yltddddpel\n",
      "\n",
      "Epoch 00008: saving model to serialized_models/shakespeare_gen.h5\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.5079 - acc: 0.0375\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "Generated string: ltdddddddd\n",
      "\n",
      "Epoch 00009: saving model to serialized_models/shakespeare_gen.h5\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.5038 - acc: 0.0469\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "Generated string: siltdddddd\n",
      "\n",
      "Epoch 00010: saving model to serialized_models/shakespeare_gen.h5\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "import pdb\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Flatten, TimeDistributed\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
    "\n",
    "num_chars = 256\n",
    "seq_len = 100\n",
    "batch_size = 32\n",
    "model_save_path = 'serialized_models/shakespeare_gen.h5'\n",
    "\n",
    "def bliteral_to_categorical(b_string):\n",
    "    # Convert byte literal representation\n",
    "    int_rep = [ord(c) for c in b_string]\n",
    "    return keras.utils.to_categorical(int_rep, num_classes=num_chars)\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    random_char = chr(np.random.randint(num_chars))\n",
    "    start_char = bliteral_to_categorical(''.join([random_char for i in range(seq_len)]))\n",
    "    curr_model_input = start_char.reshape(1, *start_char.shape)\n",
    "    for i in range(len(start_char) - 1):\n",
    "        curr_index_pred = model.predict(curr_model_input)[0, i]\n",
    "        model_next_input = np.zeros(num_chars)\n",
    "        model_next_input[np.argmax(curr_index_pred)] = 1\n",
    "        curr_model_input[0, i + 1] = model_next_input\n",
    "    \n",
    "    final_output = model.predict(curr_model_input)[0]\n",
    "    best_pred_chars = np.argmax(final_output, axis=1)\n",
    "    str_out = ''.join([chr(r) for r in best_pred_chars])\n",
    "    print('Generated string: {}'.format(str_out))\n",
    "    \n",
    "def generate_sequences(inputs, targets, seq_len, batch_size):\n",
    "    while True:\n",
    "        seq_starts = np.random.choice(len(inputs) - seq_len, batch_size)\n",
    "        X_batch = [inputs[s:s+seq_len] for s in seq_starts]\n",
    "        Y_batch = [targets[s:s+seq_len] for s in seq_starts]\n",
    "        yield np.array(X_batch), np.array(Y_batch)\n",
    "\n",
    "with open('data/hamlet.txt', 'r') as f:\n",
    "    model = Sequential([\n",
    "        LSTM(15, input_shape=(seq_len, num_chars), return_sequences=True),\n",
    "        TimeDistributed(Dense(num_chars, activation='softmax'))\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary() \n",
    "    \n",
    "    input_text = f.read()\n",
    "    \n",
    "    targets = input_text[1:]\n",
    "    input_text = input_text[:(len(input_text) - 1)]\n",
    "      \n",
    "    oh_input_chars = bliteral_to_categorical(input_text)\n",
    "    oh_targets = bliteral_to_categorical(targets)\n",
    "    steps_per_epoch = oh_input_chars.shape[0] / batch_size\n",
    "    \n",
    "    train_generator = generate_sequences(oh_input_chars, oh_targets, seq_len=seq_len, batch_size=batch_size)\n",
    "    \n",
    "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "    checkpointer = ModelCheckpoint(filepath=model_save_path, verbose=1)\n",
    "    model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=10, callbacks=[print_callback, checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Shakespeare Generator.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
